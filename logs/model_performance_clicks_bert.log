[Logging] Tee output to logs\model_performance_clicks_bert.log
======================================================================
Prediction Modeling for Ad Optimization (No IAI)
======================================================================
Target: clicks
Models: ridge, xgb, rf
Embedding method: bert
======================================================================
Loading data from data/clean...
  Train: 14100 rows, Test: 4701 rows

Features (66): Match type, Region, day_of_week, is_weekend, month...
Train shape: (14100, 66), Test shape: (4701, 66)

--- Ridge Regression (MSE) ---
  Best params: {'model__alpha': 5.0}
  Train MSE (lower is better): 108.2185
  Test  MSE (lower is better): 105.1599
  [Ridge train] mean(y)=4.7237 mean(pred)=4.7237 bias=0.0000
  [Ridge train] quantiles y: min=1 p1=1 med=2 p99=57 max=333
  [Ridge train] quantiles pred: min=-7.005 p1=-3.074 med=3.446 p99=25.11 max=28.51
  [Ridge test] mean(y)=4.7179 mean(pred)=4.5770 bias=-0.1409
  [Ridge test] quantiles y: min=1 p1=1 med=2 p99=59 max=215
  [Ridge test] quantiles pred: min=-6.794 p1=-3.51 med=3.362 p99=24.36 max=28.55
  Saved pipeline to models\ridge_bert_clicks.joblib
  Saved preprocessor to models\ridge_bert_clicks_preprocess.joblib
  Exported weights: weights_bert_clicks_numeric.csv, weights_bert_clicks_constant.csv, weights_bert_clicks_categorical.csv
  [Ridge] Global bias: -0.1409
  [Ridge] Top decile lift: 3.9320
  [Ridge] Conditional MAE: 4.4584
  [Ridge] R^2: 0.2468

--- XGBoost (MSE) ---
  Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.3, 'model__max_depth': 4, 'model__n_estimators': 20, 'model__subsample': 1.0}
  Train MSE (lower is better): 27.6276
  Test  MSE (lower is better): 39.5726
  [XGB train] mean(y)=4.7237 mean(pred)=4.7233 bias=-0.0004
  [XGB train] quantiles y: min=1 p1=1 med=2 p99=57 max=333
  [XGB train] quantiles pred: min=-3.925 p1=0.4124 med=2.565 p99=49.67 max=190
  [XGB test] mean(y)=4.7179 mean(pred)=4.7411 bias=0.0232
  [XGB test] quantiles y: min=1 p1=1 med=2 p99=59 max=215
  [XGB test] quantiles pred: min=-6.183 p1=0.4904 med=2.548 p99=50.1 max=190
  Saved model to models\xgb_mse_bert_clicks.json
  Saved preprocessor to models\xgb_mse_bert_clicks_preprocess.joblib
  [XGB] Global bias: 0.0232
  [XGB] Top decile lift: 4.7456
  [XGB] Conditional MAE: 2.5052
  [XGB] R^2: 0.7166

--- XGBoost RF (MSE) ---
  Best params: {'model__colsample_bynode': 0.9, 'model__max_depth': 4, 'model__n_estimators': 10, 'model__subsample': 0.9}
  Train MSE (lower is better): 137.8309
  Test  MSE (lower is better): 138.0701
  [RF train] mean(y)=4.7237 mean(pred)=4.7233 bias=-0.0003
  [RF train] quantiles y: min=1 p1=1 med=2 p99=57 max=333
  [RF train] quantiles pred: min=4.7 p1=4.7 med=4.706 p99=5.007 max=6.117
  [RF test] mean(y)=4.7179 mean(pred)=4.7230 bias=0.0051
  [RF test] quantiles y: min=1 p1=1 med=2 p99=59 max=215
  [RF test] quantiles pred: min=4.7 p1=4.7 med=4.706 p99=5.007 max=6.117
  Saved model to models\rf_mse_bert_clicks.json
  [RF] Global bias: 0.0051
  [RF] Top decile lift: 4.4340
  [RF] Conditional MAE: 4.8238
  [RF] R^2: 0.0111

======================================================================
Model Performance Summary (Test MSE - lower is better)
======================================================================

Target Statistics (for context):
  Mean: 4.7179
  Std Dev: 11.8175
  Variance (baseline MSE): 139.6536
  Median: 2.0000
  Min: 1.0000
  Max: 215.0000

  XGB   : MSE=39.5726 | R^2=0.7166 | bias=0.0232 | top-decile lift=4.7456 | cMAE=2.5052
  Ridge : MSE=105.1599 | R^2=0.2468 | bias=-0.1409 | top-decile lift=3.9320 | cMAE=4.4584
  RF    : MSE=138.0701 | R^2=0.0111 | bias=0.0051 | top-decile lift=4.4340 | cMAE=4.8238

Best model: XGB
======================================================================
